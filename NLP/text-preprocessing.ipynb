{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72aa703e-c71a-453f-971c-83d26fe26e66",
   "metadata": {},
   "source": [
    "##### Whenever we get the textual dataset, we first convert it into lowercase coz python is case sensitive language and wehn we tokenize the words , it may assume that  the word and Word have two different meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3975c18-d534-4ecb-a485-0d74d0ef922c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8e6864-deea-43df-944c-8be90a95e492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7592f0a4-0bb1-41a3-97d1-af67e5a32391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951c2f99-2a61-4570-8f67-ce0d041cac83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e457d6-7e1b-4136-9161-ce5681332664",
   "metadata": {},
   "source": [
    "##### Fetching any random review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a612b786-378b-48e9-8d1d-05a7fd0420c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27958b05-e4ca-4687-93b0-527d43347369",
   "metadata": {},
   "source": [
    "##### To convert this para into lowercase , we can simply use lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3d3eaa-3192-4962-aa96-abc4e8488cff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8dec4-60dc-4c31-8a03-c1c6128ccf7e",
   "metadata": {},
   "source": [
    "##### If we want to convert the whole column into lowercase , we can do as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc86075a-54fa-4ea8-ad4f-fd125b1d9096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba2a27-dfb4-412c-8361-ec9af9d8e694",
   "metadata": {},
   "source": [
    "##### Reassigning the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8edb5ac-3b00-4dd5-80fe-6b99553ae639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb4bb6-0308-48cb-a342-030a9534832f",
   "metadata": {},
   "source": [
    "##### The next step is to remove unwanted things ...like html tags and all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0a37a0-7d12-47f4-ad1a-53974976d5d7",
   "metadata": {},
   "source": [
    "##### The next step is to remove all HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df71bfdf-b2e6-4186-916e-04b00d09be67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad1ffae-6613-429d-bd90-52ff4dacb06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text=\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b87c80-3ca5-4281-bf46-38d1ab36fc98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_text=remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d59838-5fe1-44bc-8004-154740de0c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74ef97-5882-4476-bdcd-739feb455ff8",
   "metadata": {},
   "source": [
    "##### We can use the above func to clean the whole dataset using apply func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "857a3fa3-da27-43d4-bb35-fe0aab77da97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. the filming tec...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae073253-30e9-4201-b51b-04fa12bf80e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998bd174-3ffd-43b9-aa25-c2b31bf14825",
   "metadata": {},
   "source": [
    "### Removing URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41762c16-afef-4ed0-91a6-384f72a6e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1782f600-9f4d-479f-8cad-9d8d5e100a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text1=\"Hi ,I am Shreyas!!!https://github.com/Shreyasb1015 is my github link.\"\n",
    "text2=\"Find on Google:www.google.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29d2b91-9ef6-418f-acd4-6d6dbe14b539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi ,I am Shreyas!!! is my github link.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f5555f-7155-43db-b81b-bcdc462cbc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Find on Google:'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9ac89-e6d8-4c9b-ba87-2b07aa73a15e",
   "metadata": {},
   "source": [
    "### Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e665c042-e2fa-465b-97ed-80dedf403d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5095e-f49d-4512-92b7-484a593a9639",
   "metadata": {},
   "source": [
    "##### We can get the set of all punctuation marks , in english language using punctuation attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0347629c-3e53-45ff-a6ce-28f7f87f7592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0082faae-e1d2-449b-94fb-6366d557e40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9eac0324-8de9-464d-9113-b599698f200b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45c6bfb-fb87-46a7-95a7-159a25252810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text=\"How, are you man? looking good!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1344c8a9-aeee-4a8e-a5e9-d9dbbc7f2b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you man looking good'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f85e4fb-bc60-4605-908e-b9cdd7de1e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you man looking good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time.time()\n",
    "print(remove_punc(text))\n",
    "time1=time.time()-start\n",
    "time1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ae2fc-0291-4e93-b8c5-55345f8431aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Another way to remove all punctuations from the text in less time than above func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93a31f3c-bcf6-48c0-ac47-61286fb7fc22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b6587c-cbba-4675-9908-1e9a9bc80f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you man looking good'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc1(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08822f4f-55e5-43cb-b78d-936d68a9e91d",
   "metadata": {},
   "source": [
    "##### This func is 18 times faster than the func used earlier for removing punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35d5ab-0738-4297-b1a9-45a6a8d569c1",
   "metadata": {},
   "source": [
    "##### Applying this func to whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42cf0e98-c664-4c1f-ab6e-5189c34ceb93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production the filming tech...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically theres a family where a little boy j...\n",
       "4        petter matteis love in the time of money is a ...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    im going to have to disagree with the previous...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c00ccdeb-8b8a-49ea-b65c-e1cba764db4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9ffe0-6d4a-4b1c-a5b0-5444e8e32c55",
   "metadata": {},
   "source": [
    "### Chat Word Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c2525-16af-454e-8ca7-92db5d1a25d4",
   "metadata": {},
   "source": [
    "##### In this step ,we clean the words which are mostly used while chatting like slang..For e.g like rofl,lmao,ps ,etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ac59493-8548-41bf-ab52-26b4f86ddf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_words={'AFAIK':'As Far As I Know',\n",
    "'AFK':'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK':'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL':'Be Back Later',\n",
    "'BBS':'Be Back Soon',\n",
    "'BFN':'Bye For Now',\n",
    "'B4N':'Bye For Now',\n",
    "'BRB':'Be Right Back',\n",
    "'BRT':'Be Right There',\n",
    "'BTW':'By The Way',\n",
    "'B4':'Before',\n",
    "'B4N':'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA':'See You',\n",
    "'FAQ':'Frequently Asked Questions',\n",
    "'FC':'Fingers Crossed',\n",
    "'FWIW':\"For What It's Worth\",\n",
    "'FYI':\"For Your Information\",\n",
    "'GAL':\"Get A Life\",\n",
    "'GG':\"Good Game\",\n",
    "'GN':\"Good Night\",\n",
    "'GMTA':\"Great Minds Think Alike\",\n",
    "'GR8':\"Great!\",\n",
    "'G9':\"Genius\",\n",
    "'IC':\"I See\",\n",
    "'ICQ':\"I Seek you (also a chat program)\",\n",
    "'ILU':\"ILU: I Love You\",\n",
    "'IMHO':\"In My Honest/Humble Opinion\",\n",
    "'IMO':\"In My Opinion\",\n",
    "'IOW':\"In Other Words\",\n",
    "'IRL':\"In Real Life\",\n",
    "'KISS':\"Keep It Simple, Stupid\",\n",
    "'LDR':\"Long Distance Relationship\",\n",
    "'LMAO':\"Laugh My A.. Off\",\n",
    "'LOL':\"Laughing Out Loud\",\n",
    "'LTNS':\"Long Time No See\",\n",
    "'L8R':\"Later\",\n",
    "'MTE':\"My Thoughts Exactly\",\n",
    "'M8':\"Mate\",\n",
    "'NRN':\"No Reply Necessary\",\n",
    "'OIC':\"Oh I See\",\n",
    "'PITA':\"Pain In The A..\",\n",
    "'PRT':\"Party\",\n",
    "'PRW':\"Parents Are Watching\",\n",
    "'ROFL':\"Rolling On The Floor Laughing\",\n",
    "'ROFLOL':\"Rolling On The Floor Laughing Out Loud\",\n",
    "'ROTFLMAO':\"Rolling On The Floor Laughing My A.. Off\",\n",
    "'SK8':\"Skate\",\n",
    "'STATS':\"Your sex and age\",\n",
    "'ASL':\"Age, Sex, Location\",\n",
    "'THX':\"Thank You\",\n",
    "'TTFN':\"Ta-Ta For Now!\",\n",
    "'TTYL':\"Talk To You Later\",\n",
    "'U':\"You\",\n",
    "'U2':\"You Too\",\n",
    "'U4E':\"Yours For Ever\",\n",
    "'WB':\"Welcome Back\",\n",
    "'WTF':\"What The F...\",\n",
    "'WTG':\"Way To Go!\",\n",
    "'WUF':\"Where Are You From?\",\n",
    "'W8':\"Wait...\",\n",
    "'7K':\"Sick:-D Laugher\",\n",
    "'TFW' : \"That feeling when. TFW internet slang often goes in a caption to an image.\",\n",
    "'MFW' : \"My face when\",\n",
    "'MRW' : \"My reaction when\",\n",
    "'IFYP' : \"I feel your pain\",\n",
    "'LOL ': \"Laughing out loud\",\n",
    "'TNTL' : \"Trying not to laugh\",\n",
    "'JK ': 'Just kidding',\n",
    "'IDC' :' I donâ€™t care',\n",
    "'ILY' : 'I love you',\n",
    "'IMU' : 'I miss you',\n",
    "'ADIH' : 'Another day in hell',\n",
    "'IDC' : \"I donâ€™t care\",\n",
    "'ZZZ ': \"Sleeping, bored, tired\",\n",
    "'WYWH' : \"Wish you were here\",\n",
    "'TIME' : 'Tears in my eyes',\n",
    "'BAE' : 'Before anyone else',\n",
    "'FIMH ': 'Forever in my heart',\n",
    "'BSAAW' : 'Big smile and a wink',\n",
    "'BWL' : 'Bursting with laughter',\n",
    "'LMAO' : 'Laughing my a** off',\n",
    "'BFF': 'Best friends forever',\n",
    "'CSL' : 'Canâ€™t stop laughing '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd5444f6-45da-49ef-b203-88a7a9e3d980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': \"For What It's Worth\",\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'ILU: I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laughing my a** off',\n",
       " 'LOL': 'Laughing Out Loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta-Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick:-D Laugher',\n",
       " 'TFW': 'That feeling when. TFW internet slang often goes in a caption to an image.',\n",
       " 'MFW': 'My face when',\n",
       " 'MRW': 'My reaction when',\n",
       " 'IFYP': 'I feel your pain',\n",
       " 'LOL ': 'Laughing out loud',\n",
       " 'TNTL': 'Trying not to laugh',\n",
       " 'JK ': 'Just kidding',\n",
       " 'IDC': 'I donâ€™t care',\n",
       " 'ILY': 'I love you',\n",
       " 'IMU': 'I miss you',\n",
       " 'ADIH': 'Another day in hell',\n",
       " 'ZZZ ': 'Sleeping, bored, tired',\n",
       " 'WYWH': 'Wish you were here',\n",
       " 'TIME': 'Tears in my eyes',\n",
       " 'BAE': 'Before anyone else',\n",
       " 'FIMH ': 'Forever in my heart',\n",
       " 'BSAAW': 'Big smile and a wink',\n",
       " 'BWL': 'Bursting with laughter',\n",
       " 'BFF': 'Best friends forever',\n",
       " 'CSL': 'Canâ€™t stop laughing '}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d16c2e87-d6c9-4fcc-8e19-08535ed6b580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text=[]\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "            \n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    ##converting to string.\n",
    "    return \" \".join(new_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b201d6d-2d71-4820-bd9f-da2075684e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text='It was nice meeting you btw see you l8r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a009f7c2-fe32-4fb1-8b7d-6e7b093fe717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was nice meeting you By The Way see you Later'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20190291-958d-4712-947c-2b8296fc69bd",
   "metadata": {},
   "source": [
    "### Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294df98-6e8f-4d97-9778-37ac24848b0d",
   "metadata": {},
   "source": [
    "##### Wrongly written words can be misunderstood by our machine .For e.g notebook and notebk will be consider two different words by machine.We will use textblob library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7684bb8a-3d77-440c-a722-3a8ad2d69be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\bagwe\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.11.17 |       h56e8100_0         151 KB  conda-forge\n",
      "    certifi-2023.11.17         |     pyhd8ed1ab_0         155 KB  conda-forge\n",
      "    openssl-3.0.12             |       h2bbff1b_0         7.4 MB\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.08.22~ --> conda-forge::ca-certificates-2023.11.17-h56e8100_0 \n",
      "  certifi            pkgs/main/win-64::certifi-2023.7.22-p~ --> conda-forge/noarch::certifi-2023.11.17-pyhd8ed1ab_0 \n",
      "  openssl                                 3.0.10-h2bbff1b_2 --> 3.0.12-h2bbff1b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ca-certificates-2023 | 151 KB    |            |   0% \n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "textblob-0.15.3      | 595 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 155 KB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "ca-certificates-2023 | 151 KB    | #          |  11% \n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 155 KB    | #          |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "textblob-0.15.3      | 595 KB    | 2          |   3% \u001b[A\u001b[A\n",
      "ca-certificates-2023 | 151 KB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 155 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 155 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "textblob-0.15.3      | 595 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "textblob-0.15.3      | 595 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    |            |   0% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | 8          |   9% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | ##3        |  23% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | ####       |  41% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | #####4     |  55% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | ######9    |  69% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | ########1  |  82% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | #########8 |  98% \u001b[A\n",
      "\n",
      "openssl-3.0.12       | 7.4 MB    | ########## | 100% \u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb3d241a-7d62-456f-a5b8-c355bc04176a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ec33ef7-e319-4b1f-a6e3-a59726bea55f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I m going to write in my notebook and then I will give my note to friend.It should help him'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text=\"I m going to write in my notebook and then I will give my notebk to friend.It shoould hhelpp hiimi\"\n",
    "textBlb=TextBlob(incorrect_text)\n",
    "textBlb.correct().string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdf660-777f-4fa1-8a04-45852bda1baf",
   "metadata": {},
   "source": [
    "### Remvoing StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6839d24-fa2c-49d8-9181-69ff7be25bfc",
   "metadata": {},
   "source": [
    "##### Stopword are the words like --> and ,in for , or ,but,etc.If we plan to use part of speech tagging technique , we must not remove this words and should skip this step.We use nltk module to remove this stopwords.It has collections of such stopwords of different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf719fb4-f533-4c2c-8296-2292b81b4e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bagwe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f972561b-92d1-4998-8fed-e752aba7b392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181b365-0d37-4c1f-baf6-4943a632d001",
   "metadata": {},
   "source": [
    "##### We can also use it for different languages like spanish,german.It doesnt have hindi language stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b454ef47-d121-4d6b-aa76-053887e5476d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "27ac0cca-75e1-468c-a907-3655d8e4f2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text='I miss my olddays when I was in school and used to enjoy my time happily with big broad smile.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7ec047a-a7fd-4c5d-a864-9e21457bceaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I miss  olddays  I   school  used  enjoy  time happily  big broad smile.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6d35a-3d45-4f65-955d-61cce2452c18",
   "metadata": {},
   "source": [
    "### Handling emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261622af-fabd-43ec-ba04-b5d607b1be47",
   "metadata": {},
   "source": [
    "##### This is first approach , where we remove the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "259d5d3c-5cb9-4528-8208-a3b125f7adb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern=re.compile(\"[\"\n",
    "                             u\"\\U0001F600-\\U0001F64F\"  #emoticons\n",
    "                             u\"\\U0001F300-\\U0001F5FF\"  #symbols and pictographs\n",
    "                             u\"\\U0001F680-\\U0001F6FF\"   #transport and map symbols\n",
    "                             u\"\\U0001F1E0-\\U0001F1FF\"   #flags(ios)\n",
    "                             u\"\\U00002702-\\U000027B0\"\n",
    "                             u\"\\U000024C2-\\U0001F251\"\n",
    "                             \"]+\",flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e0433e1-0898-421f-b763-af5326c5b3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that was funny '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"that was funny ðŸ˜‚ðŸ˜‚ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995dfb8-3b01-4466-9e7d-1da806d7144b",
   "metadata": {},
   "source": [
    "##### Now ,we will see the second approach ,were the emojis will be replaced by the meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d70f652a-a71f-4b24-8375-b1b5e09f9760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "943adc86-6ff2-40ea-85f5-3f9c380e9dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is :fire:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('python is ðŸ”¥'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44535e-0ea8-47d1-b495-30de37390c5c",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378a297-9864-41b6-b5a8-76cfea5298e5",
   "metadata": {},
   "source": [
    "##### Tokenization is the process in which we break the text into smaller parts.Tokenization can be at word or sentence level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abf8b1-5447-4e49-947f-ae7a9e99e39a",
   "metadata": {},
   "source": [
    "##### We will use different different technqiues for tokenizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c90c1a-e285-405f-8af7-f2b1f656fb75",
   "metadata": {},
   "source": [
    "##### 1.Using the Split func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52abfb85-61e7-4632-aa3d-227dbf546804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'coding']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1=\"I love coding\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f53a8afd-6964-4cfd-95a9-f223e0c264bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am fine', 'How are you']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sentence tokenization.\n",
    "sent1=\"I am fine.How are you\"\n",
    "sent1.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce3e50-e050-4d7c-9c92-e1cf24c8306c",
   "metadata": {},
   "source": [
    "##### Problems with split func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "328b7d0e-16bf-4cc7-bb3f-6b4a771a5e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How', 'are', 'you?']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2=\"How are you?\"\n",
    "sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d5ca6c3-0f8d-45f9-82c1-869601ea39d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How are you? Where are you going']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3=\"How are you? Where are you going\"\n",
    "sent3.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1ca3f-af6e-4b35-aa78-d2632e285e13",
   "metadata": {},
   "source": [
    "##### 2.Using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6163e93-d4f5-41a2-bedf-86c1513bb40f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Kankavli']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3=\"I am going to Kankavli\"\n",
    "tokens=re.findall(\"[\\w']+\",sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a0d722e2-9013-488f-866c-19d8d699bffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am fine', 'I must chill now', 'Will I?']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4=\"I am fine. I must chill now! Will I?\"\n",
    "sentences=re.compile('[.!?] ').split(sent4)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47dfd7f-6c44-4352-a540-5341edb64b90",
   "metadata": {},
   "source": [
    "##### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0fd8d48-420a-4567-a793-e720cafa223a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3984ab00-1969-41b4-a5ba-0fb8d5c828b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'Kankavli', '!']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1=\"I am going to visit Kankavli !\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42a629b1-22b1-4deb-84e4-95c0e5dfd95b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am fine.', 'I must chill now!', 'Will I?']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2=\"I am fine. I must chill now! Will I?\"\n",
    "sent_tokenize(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f3495-bed2-47c6-a023-cd054567cd04",
   "metadata": {},
   "source": [
    "##### Trying some difficult e.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9125121-d493-4c2b-a278-50fe9d25ead7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent3=\"I have a Ph.D in A.I\"\n",
    "sent4=\"We're here to help! mail us at shreyas@gmail.com\"\n",
    "sent5=\"I will sell it at $400\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2784174c-0d3b-46fe-a7f8-dd6b815b22a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a5d3f4b3-b6bd-4ab4-9fe9-dd41a1a092ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'shreyas',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2560b348-74a0-424e-a896-b55a42ae14e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'will', 'sell', 'it', 'at', '$', '400']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5848a38-a586-43dc-ac92-6eccebe78415",
   "metadata": {},
   "source": [
    "##### We can see that nltk library is also failing to correctly classify the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30403e-ae7f-4cf9-bcf6-b281ff8af727",
   "metadata": {},
   "source": [
    "##### Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7eae29bb-0fbf-443a-bf7f-fd7644d8c6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\bagwe\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - spacy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    catalogue-2.0.10           |  py311h1ea47a8_0          43 KB  conda-forge\n",
      "    cloudpathlib-0.16.0        |     pyhd8ed1ab_0          37 KB  conda-forge\n",
      "    confection-0.1.4           |  py311h3810d55_0          88 KB  conda-forge\n",
      "    cymem-2.0.8                |  py311h12c1d0e_1          42 KB  conda-forge\n",
      "    cython-blis-0.7.10         |  py311h59ca53f_2         3.3 MB  conda-forge\n",
      "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
      "    langcodes-3.3.0            |     pyhd8ed1ab_0         156 KB  conda-forge\n",
      "    murmurhash-1.0.10          |  py311h12c1d0e_1          30 KB  conda-forge\n",
      "    openssl-3.2.0              |       hcfcfb64_1         7.9 MB  conda-forge\n",
      "    pathy-0.10.2               |     pyhd8ed1ab_0          42 KB  conda-forge\n",
      "    preshed-3.0.9              |  py311h12c1d0e_1          90 KB  conda-forge\n",
      "    python_abi-3.11            |          2_cp311           5 KB  conda-forge\n",
      "    rich-13.7.0                |     pyhd8ed1ab_0         180 KB  conda-forge\n",
      "    shellingham-1.5.4          |     pyhd8ed1ab_0          14 KB  conda-forge\n",
      "    spacy-3.7.2                |  py311h12feb9d_0         6.2 MB  conda-forge\n",
      "    spacy-legacy-3.0.12        |     pyhd8ed1ab_0          28 KB  conda-forge\n",
      "    spacy-loggers-1.0.5        |     pyhd8ed1ab_0          21 KB  conda-forge\n",
      "    srsly-2.4.8                |  py311h12c1d0e_1         657 KB  conda-forge\n",
      "    thinc-8.2.2                |  py311h12feb9d_0         1.0 MB  conda-forge\n",
      "    typer-0.9.0                |     pyhd8ed1ab_0          77 KB  conda-forge\n",
      "    ucrt-10.0.22621.0          |       h57928b3_0         1.2 MB  conda-forge\n",
      "    vc14_runtime-14.38.33130   |      h82b7239_18         732 KB  conda-forge\n",
      "    vs2015_runtime-14.38.33130 |      hcb4865c_18          17 KB  conda-forge\n",
      "    wasabi-1.1.2               |  py311h1ea47a8_0          57 KB  conda-forge\n",
      "    weasel-0.3.4               |     pyhd8ed1ab_0          42 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  catalogue          conda-forge/win-64::catalogue-2.0.10-py311h1ea47a8_0 \n",
      "  cloudpathlib       conda-forge/noarch::cloudpathlib-0.16.0-pyhd8ed1ab_0 \n",
      "  confection         conda-forge/win-64::confection-0.1.4-py311h3810d55_0 \n",
      "  cymem              conda-forge/win-64::cymem-2.0.8-py311h12c1d0e_1 \n",
      "  cython-blis        conda-forge/win-64::cython-blis-0.7.10-py311h59ca53f_2 \n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3 \n",
      "  langcodes          conda-forge/noarch::langcodes-3.3.0-pyhd8ed1ab_0 \n",
      "  murmurhash         conda-forge/win-64::murmurhash-1.0.10-py311h12c1d0e_1 \n",
      "  pathy              conda-forge/noarch::pathy-0.10.2-pyhd8ed1ab_0 \n",
      "  preshed            conda-forge/win-64::preshed-3.0.9-py311h12c1d0e_1 \n",
      "  python_abi         conda-forge/win-64::python_abi-3.11-2_cp311 \n",
      "  rich               conda-forge/noarch::rich-13.7.0-pyhd8ed1ab_0 \n",
      "  shellingham        conda-forge/noarch::shellingham-1.5.4-pyhd8ed1ab_0 \n",
      "  spacy              conda-forge/win-64::spacy-3.7.2-py311h12feb9d_0 \n",
      "  spacy-legacy       conda-forge/noarch::spacy-legacy-3.0.12-pyhd8ed1ab_0 \n",
      "  spacy-loggers      conda-forge/noarch::spacy-loggers-1.0.5-pyhd8ed1ab_0 \n",
      "  srsly              conda-forge/win-64::srsly-2.4.8-py311h12c1d0e_1 \n",
      "  thinc              conda-forge/win-64::thinc-8.2.2-py311h12feb9d_0 \n",
      "  typer              conda-forge/noarch::typer-0.9.0-pyhd8ed1ab_0 \n",
      "  ucrt               conda-forge/win-64::ucrt-10.0.22621.0-h57928b3_0 \n",
      "  vc14_runtime       conda-forge/win-64::vc14_runtime-14.38.33130-h82b7239_18 \n",
      "  wasabi             conda-forge/win-64::wasabi-1.1.2-py311h1ea47a8_0 \n",
      "  weasel             conda-forge/noarch::weasel-0.3.4-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl              pkgs/main::openssl-3.0.12-h2bbff1b_0 --> conda-forge::openssl-3.2.0-hcfcfb64_1 \n",
      "  vs2015_runtime     pkgs/main::vs2015_runtime-14.27.29016~ --> conda-forge::vs2015_runtime-14.38.33130-hcb4865c_18 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "murmurhash-1.0.10    | 30 KB     |            |   0% \n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cymem-2.0.8          | 42 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 156 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 42 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 657 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 28 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-1.1.2         | 57 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pathy-0.10.2         | 42 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataclasses-0.8      | 10 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shellingham-1.5.4    | 14 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 37 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.9        | 90 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.38 | 17 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 43 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    | 2          |   2% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    |            |   0% \u001b[A\n",
      "murmurhash-1.0.10    | 30 KB     | #####2     |  53% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 156 KB    | #          |  10% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    | ###2       |  33% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cymem-2.0.8          | 42 KB     | ###8       |  38% \u001b[A\u001b[A\u001b[A\n",
      "murmurhash-1.0.10    | 30 KB     | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 42 KB     | ###8       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | 4          |   4% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 156 KB    | #########2 |  92% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cymem-2.0.8          | 42 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 657 KB    | 2          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    | #####8     |  59% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 42 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "weasel-0.3.4         | 42 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | 7          |   8% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 28 KB     | #####7     |  57% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "langcodes-3.3.0      | 156 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-1.1.2         | 57 KB     | ##8        |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    | #########1 |  92% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 657 KB    | #####8     |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spacy-legacy-3.0.12  | 28 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #          |  10% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-1.1.2         | 57 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wasabi-1.1.2         | 57 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ######3    |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vc14_runtime-14.38.3 | 732 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #3         |  14% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataclasses-0.8      | 10 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataclasses-0.8      | 10 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shellingham-1.5.4    | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pathy-0.10.2         | 42 KB     | ###7       |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #6         |  17% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.38 | 17 KB     | #########6 |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "shellingham-1.5.4    | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 37 KB     | ####3      |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ##2        |  22% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 43 KB     | ###7       |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pathy-0.10.2         | 42 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pathy-0.10.2         | 42 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ##7        |  28% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vs2015_runtime-14.38 | 17 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.9        | 90 KB     | #7         |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    | ###4       |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ###2       |  32% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 37 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 657 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cloudpathlib-0.16.0  | 37 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "srsly-2.4.8          | 657 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    | ######1    |  61% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ###7       |  38% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | 8          |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 43 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "catalogue-2.0.10     | 43 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.9        | 90 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "preshed-3.0.9        | 90 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    | ########2  |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ####2      |  42% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #          |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ####7      |  47% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "thinc-8.2.2          | 1.0 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #3         |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #####1     |  51% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #####6     |  56% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ######     |  60% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #5         |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.22621.0    | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ######3    |  64% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ######7    |  68% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #7         |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #######1   |  72% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #######5   |  75% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #8         |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #######9   |  79% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ########3  |  83% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #9         |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ########7  |  87% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##         |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #########  |  91% \u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #########4 |  94% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##1        |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | #########8 |  98% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##2        |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##3        |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##4        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openssl-3.2.0        | 7.9 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##5        |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##6        |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##7        |  27% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##8        |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ##9        |  29% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ###        |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ###2       |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ###5       |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ####       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ####7      |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #####8     |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #######6   |  76% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | #########9 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cython-blis-0.7.10   | 3.3 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      \n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7a1fec0b-f30e-4327-81e9-9f04e6ea9e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "490900ef-8473-45ed-b7d1-e1ccfe09405e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 435.7 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/12.8 MB 655.4 kB/s eta 0:00:20\n",
      "      --------------------------------------- 0.3/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.7/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.0/12.8 MB 3.8 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 5.1 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.7/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.4/12.8 MB 7.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.9/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.5/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.8 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.3/12.8 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.6/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bagwe\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;3m[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
      "the full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af8da8b9-2b20-4cf1-b050-592bede3e721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654c2aa-b803-4a61-a502-7efd59278bf5",
   "metadata": {},
   "source": [
    "##### In avove command , we have load english small dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7c4adc37-a9ac-462b-b6cb-21593bfc95ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent3=\"I have a Ph.D in A.I\"\n",
    "sent4=\"We're here to help! mail us at shreyas@gmail.com\"\n",
    "sent5=\"I will sell it at $400\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48592eb1-7462-4714-96b7-b36414344bd8",
   "metadata": {},
   "source": [
    "##### Converting the sentences into document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9e759468-8f5d-408d-8b2d-9ef4d9c85a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc3=nlp(sent3)\n",
    "doc4=nlp(sent4)\n",
    "doc5=nlp(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f025a9c-953f-47ea-861f-694507cd0383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "have\n",
      "a\n",
      "Ph\n",
      ".\n",
      "D\n",
      "in\n",
      "A.I\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e37bf1b8-74ee-443c-9b4a-7ae003de1827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "mail\n",
      "us\n",
      "at\n",
      "shreyas@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a2ca0933-3d42-42d4-b123-e9d962f946e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "will\n",
      "sell\n",
      "it\n",
      "at\n",
      "$\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for token in doc5:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8440a-b573-448d-b901-a7dd5f291e75",
   "metadata": {},
   "source": [
    "### Stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0e459-0630-485c-949b-4430f0173083",
   "metadata": {},
   "source": [
    "##### Stemming is the technique used to deal with inflection in english.Inflection means modifying words to express tense,case ,voice ,etc.For e.g Walk,Walking,Walks.Stemming is used to reduce inflection in words to their root forms such as mapping of words to same stem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55c964-c653-408c-aec5-30a8322be04b",
   "metadata": {},
   "source": [
    "##### We have many stemmers in the nltk library.But we will mostly focus on porter stemmer and snow man stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "73f9a7bf-29df-4054-8d41-ba29d3cec0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "425c3fcd-508c-4cb9-ae4e-b16046301e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "87c7d6a4-a388-49c6-8780-ec40da05b74f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent=\"walk walks walking walked\"\n",
    "stem_words(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "50cd682e-c728-47c4-935f-91a059ead317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent=\"I am going to play as my friends have already played though i wish they should playing till now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "35412c02-0112-4251-ba11-dd6342f2618a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am go to play as my friend have alreadi play though i wish they should play till now.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e510cbf-428f-4c79-bd25-fe04d037636e",
   "metadata": {},
   "source": [
    "##### After stemming , the words which we get are not mandatory to be a valid word. It may give us different words also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03a954-e872-48c2-bba8-ac0549841eb5",
   "metadata": {},
   "source": [
    "##### This output cant be shown to anyone, as they cannot understand it .We must use lemmitization instead of this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b7ff6-6f5a-480c-8c3c-1531410e7575",
   "metadata": {},
   "source": [
    "### Lemmitization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665601d6-71db-4a08-b1c9-d4ef98ac7a52",
   "metadata": {},
   "source": [
    "##### This process ensures that the word after stemming is valid english word.It is slow compared to stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "34169484-21b1-4432-82ea-8f8406e39055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bagwe\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bc9e8-e952-45c5-bb63-72a2032ca7d9",
   "metadata": {},
   "source": [
    "##### Pos in below code refers to part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "69af384c-c543-4b22-aadd-f371496409b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "I                   I                   \n",
      "am                  be                  \n",
      "going               go                  \n",
      "to                  to                  \n",
      "play                play                \n",
      "as                  as                  \n",
      "my                  my                  \n",
      "friends             friends             \n",
      "have                have                \n",
      "already             already             \n",
      "played              play                \n",
      "though              though              \n",
      "i                   i                   \n",
      "wish                wish                \n",
      "they                they                \n",
      "should              should              \n",
      "playing             play                \n",
      "till                till                \n",
      "now                 now                 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "sentence=\"I am going to play as my friends have already played though i wish they should playing till now.\"\n",
    "punctuations='?:!.,;'\n",
    "sentence_words=nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "sentence_words\n",
    "print('{0:20}{1:20}'.format('Word','Lemma'))\n",
    "for word in sentence_words:\n",
    "    print('{0:20}{1:20}'.format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967573bc-facb-4e4c-b8de-8ec56afa03a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
